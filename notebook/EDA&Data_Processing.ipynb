{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a9bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"../data/KuaiSAR_final\"\n",
    "\n",
    "# inter = pd.read_csv(data_path + '/rec_inter.csv')\n",
    "use_cols = ['user_id', 'item_id', 'timestamp', 'click', 'like', 'follow', 'search']\n",
    "df = pd.read_csv(data_path + '/rec_inter.csv', usecols=use_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323d5068",
   "metadata": {},
   "source": [
    "## data cleaning & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c04fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning & preprocessing\n",
    "\n",
    "for c in [\"click\",\"like\",\"follow\",\"search\"]:\n",
    "    df[c] = df[c].fillna(0).astype(np.int8)\n",
    "\n",
    "# only keep recommendation interaction(none search)\n",
    "df = df[df['search'] == 0]\n",
    "\n",
    "df['pos'] = ((df['click'] + df['like'] + df['follow']) > 0).astype(np.int8)\n",
    "\n",
    "# timestamp\n",
    "ts = pd.to_numeric(df['timestamp'], errors='coerce')\n",
    "df = df[ts.notna()].copy()\n",
    "df['ts'] = ts.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c243c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 7461153 interactions\n",
      "Filtered: 2621974 interactions\n",
      "Users: 23936, Items: 50000\n",
      "Train: 2598038, Test: 23936\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Iterative Filtering (Core Stability)\n",
    "# ==========================================\n",
    "# Keep top K items to avoid OOM and reduce noise\n",
    "target_item_count = 50000\n",
    "min_user_inter = 5\n",
    "\n",
    "print(f\"Original: {len(df)} interactions\")\n",
    "\n",
    "# Filter Items first (Keep Top 50k)\n",
    "item_counts = df['item_id'].value_counts()\n",
    "if len(item_counts) > target_item_count:\n",
    "    top_items = item_counts.head(target_item_count).index\n",
    "    df_filtered = df[df['item_id'].isin(top_items)].copy()\n",
    "else:\n",
    "    df_filtered = df.copy()\n",
    "\n",
    "# Filter Users (Keep >= 5 interactions)\n",
    "# We might need a loop because removing users might reduce item counts, and vice versa\n",
    "# But for simplicity, one pass usually works well enough for coursework\n",
    "user_counts = df_filtered['user_id'].value_counts()\n",
    "valid_users = user_counts[user_counts >= min_user_inter].index\n",
    "df_filtered = df_filtered[df_filtered['user_id'].isin(valid_users)].copy()\n",
    "\n",
    "print(f\"Filtered: {len(df_filtered)} interactions\")\n",
    "print(f\"Users: {df_filtered['user_id'].nunique()}, Items: {df_filtered['item_id'].nunique()}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ID Remapping\n",
    "# ==========================================\n",
    "unique_users = df_filtered['user_id'].unique()\n",
    "unique_items = df_filtered['item_id'].unique()\n",
    "\n",
    "user2idx = {uid: i for i, uid in enumerate(unique_users)}\n",
    "item2idx = {iid: i for i, iid in enumerate(unique_items)}\n",
    "\n",
    "df_filtered['user_idx'] = df_filtered['user_id'].map(user2idx)\n",
    "df_filtered['item_idx'] = df_filtered['item_id'].map(item2idx)\n",
    "\n",
    "num_users = len(unique_users)\n",
    "num_items = len(unique_items)\n",
    "\n",
    "# ==========================================\n",
    "# 3. Train/Test Split\n",
    "# ==========================================\n",
    "df_filtered = df_filtered.sort_values(['user_idx', 'ts'])\n",
    "grouped = df_filtered.groupby('user_idx')\n",
    "test = df_filtered.loc[grouped.tail(1).index]\n",
    "train = df_filtered.drop(test.index)\n",
    "\n",
    "print(f\"Train: {len(train)}, Test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5735b",
   "metadata": {},
   "source": [
    "## Most Popular Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fc569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MostPopular] HR@50: 0.0304  NDCG@50: 0.0089\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Define Reusable Evaluation Function\n",
    "# ==========================================\n",
    "def evaluate_model(model_name, test_df, topk_preds, K=50):\n",
    "    \"\"\"\n",
    "    test_df: DataFrame with 'user_idx' and 'item_idx' (ground truth)\n",
    "    topk_preds: dict or Series, user_idx -> list of top K item_indices\n",
    "    \"\"\"\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Convert predictions to a dict for fast lookup if it isn't already\n",
    "    if not isinstance(topk_preds, dict):\n",
    "        pred_dict = topk_preds.to_dict()\n",
    "    else:\n",
    "        pred_dict = topk_preds\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        u = row['user_idx']\n",
    "        gt = row['item_idx']\n",
    "        \n",
    "        # Get recommendations for this user, default to empty if missing\n",
    "        recs = pred_dict.get(u, [])\n",
    "        \n",
    "        # HR@K\n",
    "        if gt in recs:\n",
    "            hits.append(1)\n",
    "            # NDCG@K\n",
    "            rank = recs.index(gt)\n",
    "            ndcgs.append(1.0 / np.log2(rank + 2))\n",
    "        else:\n",
    "            hits.append(0)\n",
    "            ndcgs.append(0.0)\n",
    "            \n",
    "    hr = np.mean(hits)\n",
    "    ndcg = np.mean(ndcgs)\n",
    "    print(f\"[{model_name}] HR@{K}: {hr:.4f}  NDCG@{K}: {ndcg:.4f}\")\n",
    "    return hr, ndcg\n",
    "\n",
    "# ==========================================\n",
    "# 2. Run Most Popular Baseline\n",
    "# ==========================================\n",
    "# Calculate popularity on TRAIN set only (avoid data leakage)\n",
    "# Using weighted popularity as you did before\n",
    "train['w'] = (1*train['click'] + 2*train['like'] + 3*train['follow']).astype(np.int16)\n",
    "pop_scores = train.groupby('item_idx')['w'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Get global Top-K list\n",
    "K = 50\n",
    "global_topk = pop_scores.index[:K].tolist()\n",
    "\n",
    "# Assign same topk to all test users\n",
    "most_pop_preds = {u: global_topk for u in test['user_idx'].unique()}\n",
    "\n",
    "# Evaluate\n",
    "hr_MP, ndcg_MP = evaluate_model(\"MostPopular\", test, most_pop_preds, K=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa83f2c",
   "metadata": {},
   "source": [
    "## Item CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2df237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n",
      "Sparse User-Item Matrix Shape: torch.Size([23936, 50000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Setup Device (GPU/MPS/CPU)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Prepare Indices and Values from Train Data\n",
    "indices = torch.tensor([train['user_idx'].values, train['item_idx'].values], dtype=torch.long)\n",
    "values = torch.tensor(train['w'].values, dtype=torch.float32)\n",
    "shape = torch.Size((num_users, num_items))\n",
    "\n",
    "\n",
    "# Construct User-Item Sparse Matrix\n",
    "# user_item_mat: (Users x Items)\n",
    "user_item_mat = torch.sparse_coo_tensor(indices, values, shape, device=device)\n",
    "print(f\"Sparse User-Item Matrix Shape: {user_item_mat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb0d195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0418, 0.0415,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0418, 0.0000, 0.0805,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0415, 0.0805, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Item-Item Similarity (Cosine)\n",
    "\n",
    "# Transpose to (Items x Users)\n",
    "item_user_mat = user_item_mat.t()\n",
    "\n",
    "item_user_dense = item_user_mat.to_dense()\n",
    "item_norms = torch.norm(item_user_dense, p=2, dim=1, keepdim=True)\n",
    "item_norms[item_norms == 0] = 1e-9\n",
    "item_user_norm = item_user_dense / item_norms\n",
    "sim_matrix = torch.mm(item_user_norm, item_user_norm.t()) # (Items x Items)\n",
    "\n",
    "sim_matrix.fill_diagonal_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784c531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 120/120 [08:44<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ItemCF_Torch] HR@50: 0.0547  NDCG@50: 0.0160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05472927807486631, 0.01601873472111061)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate Recommendations\n",
    "from tqdm import tqdm\n",
    "                                                         \n",
    "\n",
    "# 5. Generate Recommendations\n",
    "item_cf_preds = {}\n",
    "K = 50\n",
    "test_users_arr = test['user_idx'].unique()\n",
    "batch_size = 200 # Adjust based on memory\n",
    "\n",
    "for i in tqdm(range(0, len(test_users_arr), batch_size), desc=\"Predicting\"):\n",
    "    batch_uids = test_users_arr[i : i + batch_size]\n",
    "    batch_uids_tensor = torch.tensor(batch_uids, device=device)\n",
    "    \n",
    "    # Get History: (Batch x Items)\n",
    "    # index_select works on dense or sparse (if supported)\n",
    "    # converting batch history to dense for calculation\n",
    "    batch_hist = user_item_mat.index_select(0, batch_uids_tensor).to_dense()\n",
    "    \n",
    "    # Score: (Batch x Items) * (Items x Items) -> (Batch x Items)\n",
    "    scores = torch.mm(batch_hist, sim_matrix)\n",
    "    \n",
    "    # Mask seen items\n",
    "    scores = scores - 9999.0 * batch_hist\n",
    "    \n",
    "    # Top-K\n",
    "    _, topk_indices = torch.topk(scores, k=K, dim=1)\n",
    "    \n",
    "    # Store\n",
    "    topk_cpu = topk_indices.cpu().numpy()\n",
    "    for idx, u in enumerate(batch_uids):\n",
    "        item_cf_preds[u] = topk_cpu[idx].tolist()\n",
    "\n",
    "# 6. Evaluate\n",
    "hr_IC, ndcg_IC = evaluate_model(\"ItemCF\", test, item_cf_preds, K=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57243171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
