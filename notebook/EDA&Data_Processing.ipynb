{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a9bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"../data/KuaiSAR_final\"\n",
    "\n",
    "# inter = pd.read_csv(data_path + '/rec_inter.csv')\n",
    "use_cols = ['user_id', 'item_id', 'timestamp', 'click', 'like', 'follow', 'search']\n",
    "df = pd.read_csv(data_path + '/rec_inter.csv', usecols=use_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c04fa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning & preprocessing\n",
    "\n",
    "for c in [\"click\",\"like\",\"follow\",\"search\"]:\n",
    "    df[c] = df[c].fillna(0).astype(np.int8)\n",
    "\n",
    "# only keep recommendation interaction(none search)\n",
    "df = df[df['search'] == 0]\n",
    "\n",
    "df['pos'] = ((df['click'] + df['like'] + df['follow']) > 0).astype(np.int8)\n",
    "\n",
    "# timestamp\n",
    "ts = pd.to_numeric(df['timestamp'], errors='coerce')\n",
    "df = df[ts.notna()].copy()\n",
    "df['ts'] = ts.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c243c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original users: 25876, After filter: 23836\n",
      "Num Users: 23836, Num Items: 1232678\n",
      "Train samples: 3747178, Test samples: 23836\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Filter Sparse Users (Cold-start)\n",
    "# ==========================================\n",
    "# Keep users with at least 5 positive interactions\n",
    "min_interactions = 5\n",
    "user_counts = df[df['pos'] == 1].groupby('user_id').size()\n",
    "valid_users = user_counts[user_counts >= min_interactions].index\n",
    "df_filtered = df[df['user_id'].isin(valid_users) & (df['pos'] == 1)].copy()\n",
    "\n",
    "print(f\"Original users: {df['user_id'].nunique()}, After filter: {df_filtered['user_id'].nunique()}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ID Remapping (Critical for Matrix/DL models)\n",
    "# ==========================================\n",
    "# Create mappings\n",
    "unique_users = df_filtered['user_id'].unique()\n",
    "unique_items = df_filtered['item_id'].unique()\n",
    "\n",
    "user2idx = {uid: i for i, uid in enumerate(unique_users)}\n",
    "item2idx = {iid: i for i, iid in enumerate(unique_items)}\n",
    "\n",
    "# Invert mappings for later lookup if needed\n",
    "idx2user = {i: uid for uid, i in user2idx.items()}\n",
    "idx2item = {i: iid for iid, i in item2idx.items()}\n",
    "\n",
    "# Map to new indices\n",
    "df_filtered['user_idx'] = df_filtered['user_id'].map(user2idx)\n",
    "df_filtered['item_idx'] = df_filtered['item_id'].map(item2idx)\n",
    "\n",
    "num_users = len(unique_users)\n",
    "num_items = len(unique_items)\n",
    "print(f\"Num Users: {num_users}, Num Items: {num_items}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. Train/Test Split (Leave-One-Out)\n",
    "# ==========================================\n",
    "# Sort by user and time\n",
    "df_filtered = df_filtered.sort_values(['user_idx', 'ts'])\n",
    "\n",
    "# Group by user and split\n",
    "# last item -> test\n",
    "# rest -> train\n",
    "grouped = df_filtered.groupby('user_idx')\n",
    "test = df_filtered.loc[grouped.tail(1).index]\n",
    "train = df_filtered.drop(test.index)\n",
    "\n",
    "print(f\"Train samples: {len(train)}, Test samples: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af6fc569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MostPopular] HR@50: 0.0199  NDCG@50: 0.0058\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Define Reusable Evaluation Function\n",
    "# ==========================================\n",
    "def evaluate_model(model_name, test_df, topk_preds, K=50):\n",
    "    \"\"\"\n",
    "    test_df: DataFrame with 'user_idx' and 'item_idx' (ground truth)\n",
    "    topk_preds: dict or Series, user_idx -> list of top K item_indices\n",
    "    \"\"\"\n",
    "    hits = []\n",
    "    ndcgs = []\n",
    "    \n",
    "    # Convert predictions to a dict for fast lookup if it isn't already\n",
    "    if not isinstance(topk_preds, dict):\n",
    "        pred_dict = topk_preds.to_dict()\n",
    "    else:\n",
    "        pred_dict = topk_preds\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        u = row['user_idx']\n",
    "        gt = row['item_idx']\n",
    "        \n",
    "        # Get recommendations for this user, default to empty if missing\n",
    "        recs = pred_dict.get(u, [])\n",
    "        \n",
    "        # HR@K\n",
    "        if gt in recs:\n",
    "            hits.append(1)\n",
    "            # NDCG@K\n",
    "            rank = recs.index(gt)\n",
    "            ndcgs.append(1.0 / np.log2(rank + 2))\n",
    "        else:\n",
    "            hits.append(0)\n",
    "            ndcgs.append(0.0)\n",
    "            \n",
    "    hr = np.mean(hits)\n",
    "    ndcg = np.mean(ndcgs)\n",
    "    print(f\"[{model_name}] HR@{K}: {hr:.4f}  NDCG@{K}: {ndcg:.4f}\")\n",
    "    return hr, ndcg\n",
    "\n",
    "# ==========================================\n",
    "# 2. Run Most Popular Baseline\n",
    "# ==========================================\n",
    "# Calculate popularity on TRAIN set only (avoid data leakage)\n",
    "# Using weighted popularity as you did before\n",
    "train['w'] = (1*train['click'] + 2*train['like'] + 3*train['follow']).astype(np.int16)\n",
    "pop_scores = train.groupby('item_idx')['w'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Get global Top-K list\n",
    "K = 50\n",
    "global_topk = pop_scores.index[:K].tolist()\n",
    "\n",
    "# Assign same topk to all test users\n",
    "most_pop_preds = {u: global_topk for u in test['user_idx'].unique()}\n",
    "\n",
    "# Evaluate\n",
    "hr, ndcg = evaluate_model(\"MostPopular\", test, most_pop_preds, K=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2df237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
